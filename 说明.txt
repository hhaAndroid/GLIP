不能用 pytorch 1.10 及其高版本，因为 maskrcnn_benchamrk 不支持，如果要想成功需要修改不少代码。
目前用 pytorch1.8 cuda 10.1 gcc5.4

# 本机编译
export PATH=/usr/local/cuda-10.1/bin/:$PATH
python setup.py build develop --user


pip install nltk inflect
pip install inflect

export DATASET=/home/PJLAB/huanghaian/dataset/coco

python tools/test_grounding_net.py --config-file configs/pretrain/glip_A_Swin_T_O365.yaml --weight glip_a_tiny_o365.pth \
        TEST.IMS_PER_BATCH 1 \
        MODEL.DYHEAD.SCORE_AGG "MEAN" \
        TEST.EVAL_TASK detection \
        MODEL.DYHEAD.FUSE_CONFIG.MLM_LOSS False \
        OUTPUT_DIR output

# 单机节点 mmdet-sam 环境
pip install einops shapely timm yacs tensorboardX ftfy prettytable pymongo
pip install transformers
python setup.py build develop --user


GeneralizedVLRCNN

backbone： Swin-T
语言模型： BertEncoder


GeneralizedVLRCNN

视觉 backbone： SWINT-FPN-RETINANET
语言模型： BertEncoder
RPN: 实际上就是 RetinaNet 的 Head 部分 -- VLDYHEAD
     内部包括了视觉语义模型融合模块 -- dyhead_tower

整体架构类似 RetinaNet，也是 5 个尺度输出，每个尺度就一个 anchor，只不过多了语言模型部分，将其信息融合到视觉模型中。

假设只看 A 模型，则 dyhead_tower 中只包括视觉模型，不会对语言特征进行融合。


评估
ln -s /home/PJLAB/huanghaian/dataset/coco1/ coco

python tools/grounding_net_test.py --config-file configs/pretrain/glip_A_Swin_T_O365.yaml --weight glip_a_tiny_o365.pth OUTPUT_DIR aa
python tools/grounding_net_test.py --config-file configs/pretrain/glip_Swin_T_O365.yaml --weight glip_tiny_model_o365.pth OUTPUT_DIR aa

--config-file ../configs/pretrain/glip_Swin_T_O365.yaml --weight ../glip_tiny_model_o365.pth OUTPUT_DIR aa

python tools/grounding_net_test.py --config-file configs/pretrain/glip_A_Swin_T_O365.yaml --weight /home/huanghaian/glip_a_tiny_o365.pth \
        TEST.IMS_PER_BATCH 1 \
        TEST.EVAL_TASK detection \
        OUTPUT_DIR aa

python -m torch.distributed.launch --nproc_per_node 8 tools/grounding_net_test.py --config-file configs/pretrain/glip_A_Swin_T_O365.yaml --weight /home/huanghaian/glip_a_tiny_o365.pth \
        TEST.IMS_PER_BATCH 8 \
        TEST.EVAL_TASK detection \
        OUTPUT_DIR aa

 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790


['person. bicycle. car. motorcycle. airplane. bus. train. truck. boat. traffic light. fire hydrant. stop sign. parking meter. bench. bird. cat. dog. horse. sheep. cow. elephant. bear. zebra. giraffe. backpack. umbrella. handbag. tie. suitcase. frisbee. skis. snowboard. sports ball. kite. baseball bat. baseball glove. skateboard. surfboard. tennis racket. bottle. wine glass. cup. fork. knife. spoon. bowl. banana. apple. sandwich. orange. broccoli. carrot. hot dog. pizza. donut. cake. chair. couch. potted plant. bed. dining table. toilet. tv. laptop. mouse. remote. keyboard. cell phone. microwave. oven. toaster. sink. refrigerator. book. clock. vase. scissors. teddy bear. hair drier. toothbrush']
captions



coco fintune

需要 16 卡，暂时先用 8卡 验证是否正常训练

python -m torch.distributed.launch --nproc_per_node=8 tools/train_net.py \
       --config-file configs/pretrain/glip_A_Swin_T_O365.yaml \
       --skip-test \
       MODEL.WEIGHT ../../glip_a_tiny_o365.pth \
       DATASETS.TRAIN '("coco_grounding_train", )' \
       MODEL.BACKBONE.FREEZE_CONV_BODY_AT -1 SOLVER.IMS_PER_BATCH 16 SOLVER.USE_AMP True SOLVER.MAX_EPOCH 24 TEST.DURING_TRAINING False TEST.IMS_PER_BATCH 8 SOLVER.FIND_UNUSED_PARAMETERS False SOLVER.BASE_LR 0.00001 SOLVER.LANG_LR 0.00001 SOLVER.STEPS \(0.67,0.89\) DATASETS.DISABLE_SHUFFLE True MODEL.DYHEAD.SCORE_AGG "MEAN" TEST.EVAL_TASK detection

python -m torch.distributed.launch --nproc_per_node=16 tools/train_net.py \
       --config-file configs/pretrain/glip_A_Swin_T_O365.yaml \
       --skip-test \
       MODEL.WEIGHT ../../glip_a_tiny_o365.pth \
       DATASETS.TRAIN '("coco_grounding_train", )' \
       MODEL.BACKBONE.FREEZE_CONV_BODY_AT -1 SOLVER.IMS_PER_BATCH 32 SOLVER.USE_AMP True SOLVER.MAX_EPOCH 24 TEST.DURING_TRAINING False TEST.IMS_PER_BATCH 16 SOLVER.FIND_UNUSED_PARAMETERS False SOLVER.BASE_LR 0.00001 SOLVER.LANG_LR 0.00001 SOLVER.STEPS \(0.67,0.89\) DATASETS.DISABLE_SHUFFLE True MODEL.DYHEAD.SCORE_AGG "MEAN" TEST.EVAL_TASK detection


python tools/train_net.py --config-file configs/pretrain/glip_A_Swin_T_O365_debug.yaml MODEL.WEIGHT glip_a_tiny_o365.pth
--config-file ../configs/pretrain/glip_A_Swin_T_O365_debug.yaml MODEL.WEIGHT ../glip_a_tiny_o365.pth
